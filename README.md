# Human-Activity-Detection
In this project, a ML model was trained in order to detect the activity of the person present in the given image/video (input to the model). Further, the predicted activity that was displayed on the screen was presented in the form of audio in order to serve the main purpose of this project - help the hearing disabled people.

The project contains an ipynb file that has code snippets that show the predicted activity of the person in the image presented to the model.
